# App.py
from __future__ import annotations

import os, re, io, shutil
from datetime import datetime, date
from pathlib import Path
from typing import Optional

import numpy as np
import pandas as pd
import streamlit as st

from app_classement_unique import (
    BASE, ARCHIVE, PDF_DIR, PDF_DONE, SNAP_DIR, DATA_DIR,
    RESULTS_LOG, JOURNAL_CSV,
    RESULTS_LOG_COLUMNS, JOURNAL_COLUMNS,
    parse_money, euro, current_season_bounds,
    load_results_log_any, load_latest_master_any,
    load_journal, save_journal, append_results_log,
    extract_from_pdf, build_rows_for_log,
    standings_from_log, compute_points_table,
    compute_bubble_from_rows,
    classement_df_to_jpg, classement_points_df_to_jpg,
    archive_pdf, rollback_last_import,
    publish_public_snapshot, safe_unlink,
)

# -----------------------------------------------------------------------------
# Page config & CSS
# -----------------------------------------------------------------------------
st.set_page_config(page_title="CoronaMax", page_icon="üèÜ", layout="wide")

HIDE_CHROME = """
<style>
/* masque le menu hamburger + footer streamlit en public */
#MainMenu {visibility: hidden;}
footer {visibility: hidden;}
</style>
"""
st.markdown(HIDE_CHROME, unsafe_allow_html=True)

# -----------------------------------------------------------------------------
# Helpers UI
# -----------------------------------------------------------------------------
def list_files_sorted(root: Path, patterns: tuple[str,...] = ("*",)) -> list[Path]:
    files: list[Path] = []
    for pat in patterns:
        files.extend(root.glob(pat))
    return sorted(files, key=lambda p: p.stat().st_mtime, reverse=True)

def style_dataframe(d: pd.DataFrame) -> pd.io.formats.style.Styler:
    df = d.copy()

    # types
    int_cols = [c for c in ["Parties","Victoires","ITM","Recaves","Bulles","Place"] if c in df.columns]
    for c in int_cols:
        df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0).astype(int)

    money_cols = [c for c in ["Recaves en ‚Ç¨","Buy in","Frais","Gains","B√©n√©fices"] if c in df.columns]
    for c in money_cols:
        df[c] = pd.to_numeric(df[c].apply(parse_money), errors="coerce").fillna(0.0)

    pct_series = None
    if "% ITM" in df.columns:
        with np.errstate(divide="ignore", invalid="ignore"):
            if "ITM" in df.columns and "Parties" in df.columns:
                df["% ITM"] = (df["ITM"] / df["Parties"]).replace([np.inf, -np.inf], 0.0).fillna(0.0)
        pct_series = df["% ITM"].copy()

    sty = df.style.set_properties(**{"text-align":"center","font-size":"0.95rem","border-color":"#222"})
    sty = sty.set_table_styles([{
        "selector": "th",
        "props": [("background-color", "#e6e6e6"),
                  ("font-weight", "bold"),("color","#000"),
                  ("border","1px solid #222")]
    }])

    if "Pseudo" in df.columns:
        def _pseudo_style(col):
            out=[]
            for val in col:
                if str(val).strip().lower()=="winamax":
                    out.append("background-color:#c62828;color:#fff;font-weight:900;text-transform:uppercase;"
                               "font-family:'League Gothic', Impact, sans-serif;letter-spacing:0.5px;")
                else:
                    out.append("background-color:#f7b329;color:#000;font-weight:700;")
            return out
        sty = sty.apply(_pseudo_style, subset=["Pseudo"])

    if "Parties" in df.columns:
        sty = sty.apply(lambda s: ["color:#d00000" if v < 20 else "color:#107a10" for v in s],
                        subset=["Parties"])

    if "B√©n√©fices" in df.columns:
        vals = df["B√©n√©fices"].apply(parse_money).astype(float)
        vmin, vmax = float(np.nanmin(vals)), float(np.nanmax(vals))
        rng = (vmax - vmin) if (vmax - vmin) != 0 else 1.0
        def _benef_css(v):
            x = (parse_money(v) - vmin) / rng
            hue = int(120 * x)
            return f"background-color:hsl({hue},78%,62%); color:#111; font-weight:700;"
        sty = sty.apply(lambda s: [_benef_css(v) for v in df["B√©n√©fices"]], subset=["B√©n√©fices"])

    try:
        if "Pseudo" in df.columns:
            idx = df.index[df["Pseudo"].str.lower() == "winamax"][0]
            sty = sty.set_table_styles([{
                "selector": f"tbody tr:nth-child({idx+2})",
                "props": [("border-bottom","3px dashed #222")]
            }], overwrite=False)
    except Exception:
        pass

    fmt = {}
    for c in money_cols:
        fmt[c] = lambda x: euro(x)
    if pct_series is not None:
        fmt["% ITM"] = lambda x: f"{int(round(x*100, 0))}%" if pd.notnull(x) else "0%"
    sty = sty.format(fmt)
    return sty

def show_table(df: pd.DataFrame, caption: Optional[str] = None):
    if df is None or df.empty:
        st.info("Aucune donn√©e pour l‚Äôinstant. Va dans **Importer** pour traiter des PDFs.")
        return
    if caption:
        st.caption(caption)
    st.dataframe(style_dataframe(df), use_container_width=True, hide_index=True)


# PDF ‚Üí JPG (1re page) pour Archives
def pdf_first_page_to_jpg(pdf_path: Path, out_path: Path, dpi: int = 220) -> None:
    try:
        import fitz  # PyMuPDF
        doc = fitz.open(pdf_path)
        page = doc.load_page(0)
        pix = page.get_pixmap(dpi=dpi)
        out_path.parent.mkdir(parents=True, exist_ok=True)
        pix.save(str(out_path))
        doc.close()
        return
    except Exception:
        pass
    # fallback ‚Äúrien‚Äù
    raise RuntimeError("Conversion JPG indisponible (PyMuPDF manquant).")


# -----------------------------------------------------------------------------
# PUBLIC / ADMIN (une seule source)
# -----------------------------------------------------------------------------
IS_PUBLIC = os.getenv("CMX_MODE", "local").lower() == "public"

def _admin_key_expected() -> str:
    try:
        if "ADMIN_KEY" in st.secrets and st.secrets["ADMIN_KEY"]:
            return str(st.secrets["ADMIN_KEY"])
    except Exception:
        pass
    return os.getenv("ADMIN_KEY", "").strip() or "coronamax"

def is_admin() -> bool:
    if IS_PUBLIC:
        return False
    if os.getenv("ADMIN_MODE", "0") == "1":
        return True
    return bool(st.session_state.get("is_admin", False))

def ensure_admin() -> None:
    if not is_admin():
        st.error("‚õî Acc√®s r√©serv√© √† l‚Äôadministrateur.")
        st.stop()

with st.sidebar.expander("üîê Admin", expanded=not is_admin() and not IS_PUBLIC):
    if IS_PUBLIC:
        st.caption("Mode public : aucune action admin ici.")
    elif is_admin():
        st.success("Mode admin activ√©")
        if st.button("Se d√©connecter", key="adm_off"):
            st.session_state["is_admin"] = False
            st.rerun()
    else:
        adm_try = st.text_input("Cl√© admin", type="password", placeholder="‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢")
        if st.button("Activer", key="adm_on"):
            if adm_try.strip() == _admin_key_expected():
                st.session_state["is_admin"] = True
                st.success("Mode admin activ√©")
                st.rerun()
            else:
                st.error("Cl√© incorrecte")

NAV_PUBLIC = ["üèÜ Tableau","üë§ D√©tails joueur","üìö Archives","üèÖ Classement par points"]
NAV_ADMIN  = NAV_PUBLIC + ["‚¨ÜÔ∏è Importer","‚ôªÔ∏è R√©initialiser"]
page = st.sidebar.radio("Navigation", NAV_PUBLIC if (IS_PUBLIC or not is_admin()) else NAV_ADMIN,
                        key="nav_main")


# =============================================================================
# 1) üèÜ Tableau
# =============================================================================
if page == "üèÜ Tableau":
    st.title("Classement g√©n√©ral")

    log = load_results_log_any()
    if log is not None and not log.empty:
        s0, s1 = current_season_bounds()
        with st.expander("Filtrer par p√©riode (saison active par d√©faut)", expanded=False):
            d1 = st.date_input("Du", value=s0)
            d2 = st.date_input("Au", value=s1)
        sub = log.copy()
        sub = sub[(sub["start_time"].dt.date >= d1) & (sub["start_time"].dt.date <= d2)]
        table = standings_from_log(sub, season_only=False)
    else:
        table = load_latest_master_any()

    show_table(table)

    # Export CSV
    st.download_button("‚¨áÔ∏è Exporter (CSV affich√©)",
        data=table.to_csv(index=False).encode("utf-8"),
        file_name="classement.csv", type="secondary")

    # Export JPG
    export_cols = ["Place","Pseudo","Parties","Victoires","ITM","% ITM","Recaves","Recaves en ‚Ç¨",
                   "Bulles","Buy in","Frais","Gains","B√©n√©fices"]
    export_df = table[[c for c in export_cols if c in table.columns]].copy()

    c1, c2 = st.columns([1,3])
    with c1:
        if st.button("üñºÔ∏è Exporter en JPG"):
            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            out = SNAP_DIR / f"classement_{ts}.jpg"
            try:
                classement_df_to_jpg(export_df, out, title=None)
                st.success("JPG g√©n√©r√©.")
                st.download_button("‚¨áÔ∏è T√©l√©charger le JPG", data=out.read_bytes(),
                                   file_name=out.name, type="secondary")
            except Exception as e:
                st.error(f"Export impossible : {e}")

    # Publication snapshot (visible admin)
    if is_admin():
        st.subheader("Publication (snapshot public)")
        cc1, cc2 = st.columns(2)
        with cc1:
            if st.button("üíæ G√©n√©rer le snapshot local", key="snap_local"):
                ok, msg = publish_public_snapshot(push_to_github=False)
                (st.success if ok else st.error)("Snapshot local g√©n√©r√© ‚úÖ" if ok else "√âchec g√©n√©ration ‚ùå")
                st.caption(msg)
        with cc2:
            if st.button("üöÄ Publier sur GitHub", key="snap_push"):
                ok, msg = publish_public_snapshot(push_to_github=True, message="CoronaMax: MAJ snapshot public")
                (st.success if ok else st.error)("Publication effectu√©e ‚úÖ" if ok else "√âchec publication ‚ùå")
                st.caption(msg)
        st.caption("Local = √©crit les CSV dans data/. GitHub = m√™me chose + push dans ton d√©p√¥t public (data/**).")


# =============================================================================
# 2) üë§ D√©tails joueur
# =============================================================================

elif page == "üë§ D√©tails joueur":
    import pandas as pd
    import numpy as np
    import altair as alt
    from datetime import date
    from app_classement_unique import (
        current_season_bounds, euro, parse_money, load_results_log_any
    )

    st.title("Fiche joueur")

    log = load_results_log_any()
    if log is None or log.empty:
        st.info("Aucun historique pour l‚Äôinstant.")
        st.stop()

    # --------- Helpers robustes (colonnes variables) ----------
    def _pick_series(df: pd.DataFrame, candidates: list[str], default):
        for c in candidates:
            if c in df.columns:
                return df[c]
        return pd.Series([default] * len(df), index=df.index)

    # borne par saison (d√©faut = saison courante)
    s0, s1 = current_season_bounds()
    with st.expander("Filtrer par p√©riode (saison active par d√©faut)", expanded=False):
        d1 = st.date_input("Du", value=s0)
        d2 = st.date_input("Au", value=s1)

    # choix du joueur (sans Winamax)
    pseudos = sorted([p for p in log["Pseudo"].dropna().unique().tolist()
                      if str(p).strip().lower() != "winamax"])
    if not pseudos:
        st.info("Aucun joueur trouv√©.")
        st.stop()
    who = st.selectbox("Choisir un joueur", pseudos)

    # sous-ensemble p√©riode + joueur
    df = log.copy()
    if "start_time" in df.columns and not df["start_time"].isna().all():
        df["start_date"] = pd.to_datetime(df["start_time"]).dt.date
        df = df[(df["start_date"] >= d1) & (df["start_date"] <= d2)]
    df = df[df["Pseudo"] == who].copy()
    if df.empty:
        st.info("Pas de donn√©es pour ce joueur sur la p√©riode.")
        st.stop()

    # Colonnes clefs robustes
    pos      = pd.to_numeric(_pick_series(df, ["Position", "Place", "Rank"], 0), errors="coerce").fillna(0).astype(int)
    gaincash = _pick_series(df, ["GainsCash", "GainCash", "Gains"], 0.0).apply(parse_money).fillna(0.0)
    bounty   = _pick_series(df, ["Bounty"], 0.0).apply(parse_money).fillna(0.0)
    reentry  = pd.to_numeric(_pick_series(df, ["Reentry", "Re-entry"], 0), errors="coerce").fillna(0).astype(int)
    buyin_t  = _pick_series(df, ["buyin_total", "buy_in_total", "Buy in total"], 0.0).apply(parse_money).fillna(0.0)
    t_id     = _pick_series(df, ["tournament_id"], "").astype(str)
    t_name   = _pick_series(df, ["tournament_name"], "").astype(str)
    start_ts = pd.to_datetime(_pick_series(df, ["start_time"], pd.NaT), errors="coerce")

    # ITM (cash hors bounty)
    itm_flag = (gaincash > 0).astype(int)
    # Victoires
    win_flag = (pos == 1).astype(int)

    # -------- Bulles (corrig√©) : calcul√©es sur le log complet, puis on regarde si 'who' est le 1er non-pay√©
    def bubble_map(full_log: pd.DataFrame) -> dict:
        if full_log.empty:
            return {}
        L = {}
        g = full_log.copy()
        g["gc"] = _pick_series(g, ["GainsCash", "GainCash", "Gains"], 0.0).apply(parse_money).fillna(0.0)
        g["pos"] = pd.to_numeric(_pick_series(g, ["Position", "Place", "Rank"], 0), errors="coerce").fillna(0).astype(int)
        for tid, grp in g.groupby(_pick_series(g, ["tournament_id"], "").astype(str)):
            grp = grp.sort_values("pos")
            no_paid = grp[grp["gc"] <= 0.0]
            if no_paid.empty:
                continue
            L[tid] = str(no_paid.iloc[0]["Pseudo"])
        return L

    bubbles_by_tid = bubble_map(log)
    bubble_flag = t_id.map(lambda tid: 1 if bubbles_by_tid.get(tid) == who else 0)

    # Recaves ‚Ç¨ / Frais / Gains totaux / B√©n√©fices
    recaves_euro = reentry * buyin_t
    frais = buyin_t + recaves_euro
    gains_tot = gaincash + bounty
    benef = gains_tot - frais

    # ---- Agr√©gats
    parties    = int(len(df))
    wins       = int(win_flag.sum())
    itm        = int(itm_flag.sum())
    pct_itm    = (itm / parties) * 100 if parties else 0.0
    bulles     = int(bubble_flag.sum())
    recaves_nb = int(reentry.sum())
    recaves_e  = float(recaves_euro.sum())
    buyins     = float(buyin_t.sum())
    total_fees = float(frais.sum())
    g_cash     = float(gaincash.sum())
    g_bounty   = float(bounty.sum())
    g_total    = float(gains_tot.sum())
    net        = float(benef.sum())
    roi_total  = (g_total - total_fees) / total_fees if total_fees > 0 else 0.0  # ROI sur gains totaux uniquement
    avg_finish = float(pos.replace(0, np.nan).mean()) if (pos > 0).any() else 0.0

    # Points (formule N_participants - pos + 1, min=1) sur la p√©riode
    log_period = log.copy()
    if "start_time" in log_period.columns and not log_period["start_time"].isna().all():
        log_period["start_date"] = pd.to_datetime(log_period["start_time"]).dt.date
        log_period = log_period[(log_period["start_date"] >= d1) & (log_period["start_date"] <= d2)]
    lp_pos   = pd.to_numeric(_pick_series(log_period, ["Position", "Place", "Rank"], 0), errors="coerce").fillna(0).astype(int)
    lp_tid   = _pick_series(log_period, ["tournament_id"], "").astype(str)
    lp_pseudo= _pick_series(log_period, ["Pseudo"], "").astype(str)

    if not log_period.empty:
        n_part = log_period.groupby(lp_tid).transform("size")
        pts_row = (n_part - lp_pos + 1).clip(lower=1)
        pts_total = int(pts_row[lp_pseudo == who].sum())
    else:
        pts_total = 0

    # ---- TUILES (comme avant)
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("Parties", parties)
    c2.metric("Victoires", wins)
    c3.metric("ITM", f"{itm} ({pct_itm:.0f}%)")
    c4.metric("Bulles", bulles)

    c5, c6, c7, c8 = st.columns(4)
    c5.metric("Buy-ins", euro(buyins))
    c6.metric("Recaves (nb)", recaves_nb)
    c7.metric("Recaves en ‚Ç¨", euro(recaves_e))
    c8.metric("Frais totaux", euro(total_fees))

    c9, c10, c11, c12 = st.columns(4)
    c9.metric("Gains (cash)", euro(g_cash))
    c10.metric("Bounty", euro(g_bounty))
    c11.metric("Gains totaux", euro(g_total))
    c12.metric("B√©n√©fices", euro(net))

    c13, c14, c15 = st.columns(3)
    c13.metric("Place moyenne", f"{avg_finish:.2f}" if avg_finish else "‚Äî")
    c14.metric("Points", pts_total)
    c15.metric("ROI (total)", f"{roi_total:.0%}")

    # ---- Graphiques
    st.subheader("√âvolution des b√©n√©fices (cumul)")
    evo = pd.DataFrame({
        "Date": start_ts,
        "B√©n√©fices": benef
    }).dropna(subset=["Date"]).sort_values("Date")
    if not evo.empty:
        evo["Cumul"] = evo["B√©n√©fices"].cumsum()
        st.altair_chart(
            alt.Chart(evo).mark_line(point=True).encode(
                x="Date:T", y="Cumul:Q"
            ).properties(height=300),
            use_container_width=True
        )
    else:
        st.caption("Aucune donn√©e temporelle exploitable.")

    st.subheader("Distribution des places")
    places = pos[pos > 0]
    if not places.empty:
        dist = places.value_counts().sort_index().reset_index()
        dist.columns = ["Place", "Occurrences"]
        st.altair_chart(
            alt.Chart(dist).mark_bar().encode(
                x=alt.X("Place:O", sort="ascending"),
                y="Occurrences:Q"
            ).properties(height=260),
            use_container_width=True
        )
    else:
        st.caption("Aucune place enregistr√©e.")

    # ---- Historique d√©taill√©
    st.subheader("Historique")
    hist = pd.DataFrame({
        "Date": start_ts.dt.strftime("%Y-%m-%d %H:%M"),
        "Tournoi": t_name,
        "Place": pos,
        "Reentry": reentry,
        "Buy in": buyin_t.apply(euro),
        "Frais": frais.apply(euro),
        "GainsCash": gaincash.apply(euro),
        "Bounty": bounty.apply(euro),
        "Gains": gains_tot.apply(euro),
        "B√©n√©fices": benef.apply(euro),
    })
    hist = hist.sort_values("Date")
    st.dataframe(hist, use_container_width=True, hide_index=True)



# =============================================================================
# 3) üìö Archives
# =============================================================================
elif page == "üìö Archives":
    st.title("Archives")

    # Classement ‚Äú√† la date‚Äù (bas√© sur la DATE DE TOURNOI)
    st.subheader("Classement ¬´ √† la date ¬ª")
    log = load_results_log_any()
    if log.empty:
        st.info("Pas d‚Äôhistorique pour le moment.")
    else:
        d = st.date_input("Afficher l‚Äô√©tat au", value=date.today())
        sub = log[log["start_time"].dt.date <= d].copy()
        table = standings_from_log(sub, season_only=False)
        show_table(table, caption=f"√âtat arr√™t√© au {d:%d/%m/%Y}")

    # PDFs archiv√©s
    st.subheader("PDFs archiv√©s (par saison)")
    # utiliser les PDFs du snapshot en public, et l‚Äôarchive locale en admin/local
    from app_classement_unique import DATA_DIR  # <-- assure-toi que c‚Äôest import√© en haut si pas d√©j√†

    src_dir = (DATA_DIR / "PDF_Traites") if IS_PUBLIC else PDF_DONE
    pdfs = list_files_sorted(src_dir, ("*.pdf",))

    if not pdfs:
        st.caption("Aucun PDF archiv√©.")
    else:
        with st.expander("Saison courante", expanded=True):
            for p in pdfs:
                cols = st.columns([6, 2, 2])
                cols[0].write(f"**{p.name}**  \n_{datetime.fromtimestamp(p.stat().st_mtime):%Y-%m-%d %H:%M}_")
                with cols[1]:
                    st.download_button("T√©l√©charger (PDF)", data=p.read_bytes(),
                                       file_name=p.name, type="secondary", key=f"dlpdf_{p.name}")
                with cols[2]:
                    try:
                        jpg_path = SNAP_DIR / "archived_jpg" / (p.stem + ".jpg")
                        need_regen = (not jpg_path.exists()) or (jpg_path.stat().st_mtime < p.stat().st_mtime)
                        if need_regen:
                            pdf_first_page_to_jpg(p, jpg_path, dpi=220)
                        st.download_button("T√©l√©charger (JPG)", data=jpg_path.read_bytes(),
                                           file_name=jpg_path.name, type="secondary", key=f"dljpg_{p.name}")
                    except Exception as e:
                        st.button("JPG indisponible", disabled=True, key=f"nojpg_{p.name}")
                        st.caption(f"‚ö†Ô∏è Conversion JPG √©chou√©e : {e}")


# =============================================================================
# 4) üèÖ Classement par points
# =============================================================================
elif page == "üèÖ Classement par points":
    st.title("Classement g√©n√©ral ‚Äî Points")

    log = load_results_log_any()
    if log is None or log.empty:
        st.info("Aucune donn√©e pour l‚Äôinstant. Va dans **Importer** pour traiter des PDFs.")
    else:
        s0, s1 = current_season_bounds()
        with st.expander("Filtrer par p√©riode (saison active par d√©faut)", expanded=False):
            d1 = st.date_input("Du", value=s0)
            d2 = st.date_input("Au", value=s1)

        pts = compute_points_table(log, d1, d2)
        if pts.empty:
            st.info("Pas de r√©sultats sur cette p√©riode.")
        else:
            st.dataframe(pts, use_container_width=True, hide_index=True)
            st.download_button("‚¨áÔ∏è Exporter (CSV Points)",
                data=pts.to_csv(index=False).encode("utf-8"),
                file_name="classement_points.csv", type="secondary")

            c1, c2 = st.columns([1, 2])
            with c1:
                if st.button("üñºÔ∏è Exporter le classement Points en JPG"):
                    try:
                        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
                        jpg_path = SNAP_DIR / f"classement_points_{ts}.jpg"
                        classement_points_df_to_jpg(pts, jpg_path)
                        st.session_state["last_points_jpg_export"] = str(jpg_path)
                        st.success("JPG (Points) g√©n√©r√©.")
                    except Exception as e:
                        st.error(f"Export impossible : {e}")
            with c2:
                jp = st.session_state.get("last_points_jpg_export")
                if jp and Path(jp).exists():
                    st.download_button("‚¨áÔ∏è T√©l√©charger le JPG (Points)",
                        data=Path(jp).read_bytes(),
                        file_name=Path(jp).name, type="secondary")


# =============================================================================
# 5) ‚¨ÜÔ∏è Importer (ADMIN)
# =============================================================================
elif page == "‚¨ÜÔ∏è Importer":
    ensure_admin()
    st.title("Importer des r√©sultats (PDF Winamax)")
    if "pending_tourneys" not in st.session_state:
        st.session_state["pending_tourneys"] = {}

    up = st.file_uploader("D√©posez un ou plusieurs PDFs", type=["pdf"], accept_multiple_files=True)
    if up and st.button("Analyser et mettre en file", type="primary"):
        logs = []
        for f in up:
            tmp = PDF_DIR / f.name
            tmp.write_bytes(f.read())
            try:
                parsed = extract_from_pdf(tmp)
                rows_preview = build_rows_for_log(parsed)
                if rows_preview.empty:
                    st.warning(f"‚ö†Ô∏è {f.name} : 0 ligne d√©tect√©e (non ajout√©).")
                    safe_unlink(tmp)
                    continue
                st.session_state.pending_tourneys[parsed.tournament_id] = {
                    "df": rows_preview,
                    "src_path": str(tmp),
                    "name": parsed.tournament_name,
                    "start_time": parsed.start_time,
                }
                logs.append(f"‚úÖ Ajout√© : {f.name} ‚Äî {len(rows_preview)} ligne(s)")
            except Exception as e:
                safe_unlink(tmp)
                logs.append(f"‚ùå Erreur sur {f.name} : {e}")
        if logs:
            st.text("\n".join(logs))
        st.info("Faites d√©filer pour valider chaque tournoi.")

    if not st.session_state.pending_tourneys:
        st.caption("Aucun tournoi en attente de validation.")
    else:
        st.subheader("Tournois en attente de validation")
        to_rerun = False

        for tid, item in list(st.session_state.pending_tourneys.items()):
            st.markdown(f"**{item['name']} ‚Äî {pd.to_datetime(item['start_time']):%d/%m/%Y %H:%M}**")
            edit = st.data_editor(
                item["df"], num_rows="dynamic", width="stretch", hide_index=True, key=f"edit_{tid}"
            )
            bubble_name = compute_bubble_from_rows(edit)
            st.info(f"**Bulle d√©tect√©e :** {bubble_name or '(aucune)'}")

            c1, c2 = st.columns(2)
            with c1:
                if st.button("‚úÖ Valider ce tournoi", key=f"commit_{tid}"):
                    # 1) Append au log
                    append_results_log(edit.copy())

                    # 2) Journal + archivage du PDF
                    journal = load_journal()
                    journal.loc[len(journal)] = {
                        "sha1": tid,
                        "filename": Path(item["src_path"]).name,
                        "processed_at": datetime.now(),
                    }
                    save_journal(journal)
                    archive_pdf(Path(item["src_path"]))
                    del st.session_state.pending_tourneys[tid]

                    # 3) Rebuild des snapshots (gains + points + miroirs publics)
                    from app_classement_unique import (
                        load_results_log_any,
                        standings_from_log,
                        compute_points_table,
                        current_season_bounds,
                        DATA_DIR,
                    )

                    cur_log = load_results_log_any()
                    table_gains = standings_from_log(cur_log, season_only=False)

                    # Points sur la saison courante
                    s0, s1 = current_season_bounds()
                    table_points = compute_points_table(cur_log, d1=s0, d2=s1)

                    DATA_DIR.mkdir(parents=True, exist_ok=True)

                    # Gains
                    (DATA_DIR / "latest_master.csv").write_text(
                        table_gains.to_csv(index=False), encoding="utf-8"
                    )
                    # Points (saison en cours)
                    (DATA_DIR / "points_table.csv").write_text(
                        table_points.to_csv(index=False), encoding="utf-8"
                    )
                    # Journal public
                    (DATA_DIR / "journal.csv").write_text(
                        journal.to_csv(index=False), encoding="utf-8"
                    )
                    # Miroir du results_log (utile si append_results_log ne le fait pas d√©j√†)
                    try:
                        (DATA_DIR / "results_log.csv").write_text(
                            cur_log.to_csv(index=False), encoding="utf-8"
                        )
                    except Exception as e:
                        print(f"[Importer] WARNING: miroir data/results_log.csv KO: {e}")

                    # 4) Diagnostics
                    st.caption(f"üìÑ ARCHIVE/results_log.csv ‚Üí {len(cur_log)} lignes")
                    st.caption(f"üßÆ latest_master.csv: {len(table_gains)} lignes")
                    st.caption(f"üèÖ points_table.csv: {len(table_points)} lignes")

                    st.success("Tournoi ajout√©. Classement mis √† jour.")
                    to_rerun = True

            with c2:
                if st.button("üóëÔ∏è Annuler / retirer de la file", key=f"cancel_{tid}"):
                    safe_unlink(Path(item["src_path"]))
                    del st.session_state.pending_tourneys[tid]
                    st.warning("Tournoi retir√© de la file.")
                    to_rerun = True

            st.divider()

        if to_rerun:
            st.rerun()

        # Rollback
        st.subheader("Annuler le dernier import")
        if st.button("üßπ Annuler le dernier tournoi import√©"):
            info = rollback_last_import()
            if info.get("ok"):
                st.success(f"{info['msg']} ‚Äî PDF remis: {info.get('pdf_back','')}")
                st.rerun()
            else:
                st.info(info.get("msg", "Rien √† annuler."))


# =============================================================================
# 6) ‚ôªÔ∏è R√©initialiser (ADMIN)
# =============================================================================
elif page == "‚ôªÔ∏è R√©initialiser":
    ensure_admin()
    st.title("R√©initialiser la saison courante")
    st.warning("Attention : remise √† z√©ro des agr√©gats. Les PDFs archiv√©s peuvent √™tre re-trait√©s ensuite.")

    do_move = st.checkbox("Remettre les PDFs archiv√©s dans ¬´ PDF_A_TRAITER ¬ª (suppression horodatage)", value=True)

    if st.button("‚ö†Ô∏è Lancer la r√©initialisation", type="primary"):
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        BACKUPS_DIR = RESULTS_LOG.parent / "BACKUPS"
        BACKUPS_DIR.mkdir(parents=True, exist_ok=True)
        try:
            if RESULTS_LOG.exists():
                shutil.copy2(RESULTS_LOG, BACKUPS_DIR / f"results_log_{ts}.csv")
        except Exception as e:
            st.warning(f"Backup rat√© pour results_log.csv : {e}")
        try:
            if JOURNAL_CSV.exists():
                shutil.copy2(JOURNAL_CSV, BACKUPS_DIR / f"journal_{ts}.csv")
        except Exception as e:
            st.warning(f"Backup rat√© pour journal.csv : {e}")

        pd.DataFrame(columns=RESULTS_LOG_COLUMNS).to_csv(RESULTS_LOG, index=False, encoding="utf-8")
        pd.DataFrame(columns=JOURNAL_COLUMNS).to_csv(JOURNAL_CSV, index=False, encoding="utf-8")

        if do_move:
            PDF_DIR.mkdir(parents=True, exist_ok=True)

            def _unique_dest(base_dir: Path, name: str) -> Path:
                dest = base_dir / name
                if not dest.exists():
                    return dest
                stem, suffix = Path(name).stem, Path(name).suffix
                n = 1
                while True:
                    cand = base_dir / f"{stem}_dup{n}{suffix}"
                    if not cand.exists():
                        return cand
                    n += 1

            for p in list_files_sorted(PDF_DONE, ("*.pdf",)):
                clean_name = (p.name.split("__")[0] + ".pdf") if "__" in p.name else p.name
                dst = _unique_dest(PDF_DIR, clean_name)
                try:
                    shutil.move(str(p), str(dst))
                except Exception as e:
                    st.warning(f"Impossible de d√©placer {p.name} -> {dst.name} : {e}")

        st.success("R√©initialisation OK. Allez dans **Importer** pour revalider.")
